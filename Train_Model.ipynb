{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1 Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step2 Split the dataset into Training set and Test set\n",
    "import splitfolders  # or import split_folders\n",
    "\n",
    "# Split with a ratio.\n",
    "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "splitfolders.ratio(\"flowers\", output=\"Output\", seed=1337, ratio=(.75, 0, .25), group_prefix=None) # default values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: numpy in c:\\users\\s-n_e\\appdata\\roaming\\python\\python38\\site-packages (1.19.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Error checking for conflicts.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\s-n_e\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 3021, in _dep_map\n",
      "    return self.__dep_map\n",
      "  File \"C:\\Users\\s-n_e\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 2815, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _DistInfoDistribution__dep_map\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\s-n_e\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 3012, in _parsed_pkg_info\n",
      "    return self._pkg_info\n",
      "  File \"C:\\Users\\s-n_e\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 2815, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _pkg_info\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\s-n_e\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 512, in _warn_about_conflicts\n",
      "    package_set, _dep_info = check_install_conflicts(to_install)\n",
      "  File \"C:\\Users\\s-n_e\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\check.py\", line 114, in check_install_conflicts\n",
      "    package_set, _ = create_package_set_from_installed()\n",
      "  File \"C:\\Users\\s-n_e\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\check.py\", line 53, in create_package_set_from_installed\n",
      "    package_set[name] = PackageDetails(dist.version, dist.requires())\n",
      "  File \"C:\\Users\\s-n_e\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 2736, in requires\n",
      "    dm = self._dep_map\n",
      "  File \"C:\\Users\\s-n_e\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 3023, in _dep_map\n",
      "    self.__dep_map = self._compute_dependencies()\n",
      "  File \"C:\\Users\\s-n_e\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 3032, in _compute_dependencies\n",
      "    for req in self._parsed_pkg_info.get_all('Requires-Dist') or []:\n",
      "  File \"C:\\Users\\s-n_e\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 3014, in _parsed_pkg_info\n",
      "    metadata = self.get_metadata(self.PKG_INFO)\n",
      "  File \"C:\\Users\\s-n_e\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 1420, in get_metadata\n",
      "    value = self._get(path)\n",
      "  File \"C:\\Users\\s-n_e\\anaconda3\\lib\\site-packages\\pip\\_vendor\\pkg_resources\\__init__.py\", line 1616, in _get\n",
      "    with open(path, 'rb') as stream:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'c:\\\\users\\\\s-n_e\\\\anaconda3\\\\lib\\\\site-packages\\\\widgetsnbextension-3.5.1.dist-info\\\\METADATA'\n"
     ]
    }
   ],
   "source": [
    "pip install numpy -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.19.3\n",
      "  Downloading numpy-1.19.3-cp38-cp38-win_amd64.whl (13.3 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.4\n",
      "    Uninstalling numpy-1.19.4:\n",
      "      Successfully uninstalled numpy-1.19.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'C:\\\\Users\\\\s-n_e\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.19.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step3 Create Python program to read the Training set images and create a tabular dataset\n",
    "import os\n",
    "import cv2 \n",
    "\n",
    "from skimage import feature\n",
    " \n",
    "images_train = []\n",
    "labels_train = []\n",
    "images_test = []\n",
    "labels_test = []\n",
    "#lst = []\n",
    "# get all the image folder paths \n",
    "image_paths = os.listdir('Output/train') \n",
    "for path in image_paths:\n",
    "    # get all the image names\n",
    "    all_images_train = os.listdir(f\"Output/train/{path}\")\n",
    "    all_images_test = os.listdir(f\"Output/test/{path}\")\n",
    "\n",
    "    # iterate over the image names, get the label\n",
    "    for image_train in all_images_train:\n",
    "        image_path_train = f\"Output/train/{path}/{image_train}\"\n",
    "        image_train = cv2.imread(image_path_train)\n",
    "        image_train = cv2.resize(image_train, (128, 256))\n",
    "\n",
    "        # get the HOG descriptor for the image\n",
    "        hog_desc_train = feature.hog(image_train, orientations=9, pixels_per_cell=(8, 8),\n",
    "            cells_per_block=(2, 2), transform_sqrt=True, block_norm='L2-Hys')\n",
    "    \n",
    "        # update the data and labels\n",
    "        images_train.append(hog_desc_train)\n",
    "        labels_train.append(path) \n",
    "        \n",
    "    # iterate over the image names, get the label\n",
    "    for image_test in all_images_test:\n",
    "        image_path_test = f\"Output/test/{path}/{image_test}\"\n",
    "        image_test = cv2.imread(image_path_test)\n",
    "        image_test = cv2.resize(image_test, (128, 256))\n",
    "\n",
    "        # get the HOG descriptor for the image\n",
    "        hog_desc_test = feature.hog(image_test, orientations=9, pixels_per_cell=(8, 8),\n",
    "            cells_per_block=(2, 2), transform_sqrt=True, block_norm='L2-Hys')\n",
    "    \n",
    "        # update the data and labels\n",
    "        images_test.append(hog_desc_test)\n",
    "        labels_test.append(path) \n",
    "        \n",
    "        \"\"\"#add features and label in the same tabular dataset without split\n",
    "        test01=hog_desc.tolist()\n",
    "        test01.append(path) \n",
    "        lst.append(test01)\"\"\"\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.8.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#to tabulate dataset\n",
    "#pip install tabulate\n",
    "\n",
    "#from tabulate import tabulate\n",
    "#table =tabulate(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-465409eaab28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Pandas DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lst' is not defined"
     ]
    }
   ],
   "source": [
    "#Pandas DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(lst)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "#Step4 Build and train a classifier model: naive_bayes \n",
    "from sklearn.naive_bayes import GaussianNB as gnb\n",
    "# Creating the classifier object\n",
    "model = gnb()\n",
    " \n",
    "# Performing training\n",
    "model.fit(images_train, labels_train) \n",
    "# Predicton on test \n",
    "y_pred = model.predict(images_test) \n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(labels_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "  \n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(model, 'trained_model.pkl') \n",
    "  \n",
    "# Load the model from the file \n",
    "naive_bayes_from_joblib = joblib.load('trained_model.pkl')  \n",
    "  \n",
    "# Use the loaded model to make predictions \n",
    "#naive_bayes_from_joblib.predict(images_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test images...\n"
     ]
    }
   ],
   "source": [
    "# predict on the test images\n",
    "print('Evaluating on test images...')\n",
    "# loop over the test dataset folders\n",
    "for (i, imagePath) in enumerate(os.listdir(f\"test_images/flowers/\")):\n",
    "    image = cv2.imread(f\"test_images/flowers/{imagePath}\")\n",
    "    resized_image = cv2.resize(image, (128, 256))\n",
    "    # get the HOG descriptor for the test image\n",
    "    (hog_desc, hog_image) = feature.hog(resized_image, orientations=9, pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(2, 2), transform_sqrt=True, block_norm='L2-Hys', visualize=True)\n",
    "    # prediction\n",
    "    pred = model.predict(hog_desc.reshape(1, -1))[0]\n",
    "    # convert the HOG image to appropriate data type. We do...\n",
    "    # ... this instead of rescaling the pixels from 0. to 255.\n",
    "    hog_image = hog_image.astype('float64')\n",
    "    # show thw HOG image\n",
    "    cv2.imshow('HOG Image', hog_image)\n",
    "    # put the predicted text on the test image\n",
    "    cv2.putText(image, pred.title(), (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.0,\n",
    "        (0, 255, 0), 2) \n",
    "    cv2.imshow('Test Image', image)\n",
    "    cv2.imwrite(f\"outputs/flowers_hog_{i}.jpg\", hog_image*255.) # multiply by 255. to bring to OpenCV pixel range\n",
    "    cv2.imwrite(f\"outputs/flowers_pred_{i}.jpg\", image)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastai\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torchvision>=0.8 (from fastai) (from versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.5.0)\n",
      "ERROR: No matching distribution found for torchvision>=0.8 (from fastai)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading fastai-2.1.10-py3-none-any.whl (190 kB)\n",
      "Requirement already satisfied: pip in c:\\users\\s-n_e\\anaconda3\\lib\\site-packages (from fastai) (20.1.1)\n",
      "Collecting fastcore>=1.3.8\n",
      "  Downloading fastcore-1.3.13-py3-none-any.whl (52 kB)\n",
      "Collecting spacy\n",
      "  Downloading spacy-2.3.5-cp38-cp38-win_amd64.whl (9.7 MB)\n",
      "Requirement already satisfied: pillow>6.0.0 in c:\\users\\s-n_e\\anaconda3\\lib\\site-packages (from fastai) (7.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\s-n_e\\anaconda3\\lib\\site-packages (from fastai) (0.23.1)\n"
     ]
    }
   ],
   "source": [
    "pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c pytorch -c fastai fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import load_learner\n",
    "import open_image\n",
    "from flask_cors import CORS,cross_origin\n",
    "app = Flask(__name__)\n",
    "CORS(app, support_credentials=True)\n",
    "\n",
    "# load the learner\n",
    "learn = load_learner(path='./models', file='trained_model.pkl')\n",
    "classes = learn.data.classes\n",
    "\n",
    "\n",
    "def predict_single(img_file):\n",
    "    'function to take image and return prediction'\n",
    "    prediction = learn.predict(open_image(img_file))\n",
    "    probs_list = prediction[2].numpy()\n",
    "    return {\n",
    "        'category': classes[prediction[1].item()],\n",
    "        'probs': {c: round(float(probs_list[i]), 5) for (i, c) in enumerate(classes)}\n",
    "    }\n",
    "\n",
    "\n",
    "# route for prediction\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    return jsonify(predict_single(request.files['image']))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
